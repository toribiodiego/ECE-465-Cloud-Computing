{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install ray[tune]\n",
        "!pip install ray[default]\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rJ3UhC43zMQC",
        "outputId": "99b28625-b9e1-470c-9664-4451bf66d2d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (5.29.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.2.2)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (18.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=1.9->ray[tune]) (2.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->ray[tune]) (4.12.2)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.44.1 tensorboardX-2.6.2.2\n",
            "Requirement already satisfied: ray[default] in /usr/local/lib/python3.11/dist-packages (2.44.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray[default]) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray[default]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray[default]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[default]) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray[default]) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray[default]) (5.29.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray[default]) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray[default]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray[default]) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray[default]) (2.32.3)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.11/dist-packages (from ray[default]) (3.11.14)\n",
            "Collecting aiohttp_cors (from ray[default])\n",
            "  Downloading aiohttp_cors-0.8.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default])\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default])\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default]) (1.71.0)\n",
            "Collecting opencensus (from ray[default])\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.11/dist-packages (from ray[default]) (2.10.6)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default]) (0.21.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.11/dist-packages (from ray[default]) (7.1.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default])\n",
            "  Downloading virtualenv-20.29.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default]) (2.6.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default]) (25.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default]) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default]) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default]) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]) (4.12.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default])\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]) (4.3.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[default]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[default]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[default]) (0.23.1)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default]) (1.17.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default]) (2.24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray[default]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray[default]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray[default]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray[default]) (2025.1.31)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open->ray[default]) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.69.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (2.38.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.6.1)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.29.3-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.0-py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Installing collected packages: py-spy, opencensus-context, distlib, colorful, virtualenv, aiohttp_cors, opencensus\n",
            "Successfully installed aiohttp_cors-0.8.0 colorful-0.5.6 distlib-0.3.9 opencensus-0.11.4 opencensus-context-0.1.3 py-spy-0.4.0 virtualenv-20.29.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UVUmmJMqw5ev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1293681f-94e7-4f43-98d6-95f27b777203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtoribio-diego23\u001b[0m (\u001b[33mCooper-Union\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL for Ray Dashboard: NgrokTunnel: \"https://748d-35-240-222-110.ngrok-free.app\" -> \"http://localhost:8265\"\n",
            "Ray available resources: {'accelerator_type:L4': 1.0, 'node:__internal_head__': 1.0, 'CPU': 12.0, 'memory': 39565255476.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 16956538060.0, 'GPU': 1.0}\n",
            "+--------------------------------------------------------+\n",
            "| Configuration for experiment     mnist_ray_tune        |\n",
            "+--------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator |\n",
            "| Scheduler                        FIFOScheduler         |\n",
            "| Number of trials                 12                    |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/mnist_ray_tune\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-03-31_01-34-54_021914_1311/artifacts/2025-03-31_01-34-57/mnist_ray_tune/driver_artifacts`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(train_model pid=4539)\u001b[0m wandb: Currently logged in as: toribio-diego23 (Cooper-Union) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "\u001b[36m(train_model pid=4539)\u001b[0m wandb: Tracking run with wandb version 0.19.8\n",
            "\u001b[36m(train_model pid=4539)\u001b[0m wandb: Run data is saved locally in /tmp/ray/session_2025-03-31_01-34-54_021914_1311/artifacts/2025-03-31_01-34-57/mnist_ray_tune/working_dirs/train_model_5aa5c_00000_0_batch_size=128,dropout_rate=0.4329,layer_size=147,lr=0.0074,optimizer=adam_2025-03-31_01-34-57/wandb/run-20250331_013506-0eccc1w9\n",
            "\u001b[36m(train_model pid=4539)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
            "\u001b[36m(train_model pid=4539)\u001b[0m wandb: Syncing run feasible-microwave-61\n",
            "\u001b[36m(train_model pid=4539)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/Cooper-Union/mnist_ray_tune\n",
            "\u001b[36m(train_model pid=4539)\u001b[0m wandb: 🚀 View run at https://wandb.ai/Cooper-Union/mnist_ray_tune/runs/0eccc1w9\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: 🚀 View run at https://wandb.ai/Cooper-Union/mnist_ray_tune/runs/ypwymmzr\n",
            "  0%|          | 0.00/9.91M [00:00<?, ?B/s]\n",
            "  0%|          | 32.8k/9.91M [00:00<01:05, 150kB/s]\n",
            "\u001b[36m(train_model pid=4547)\u001b[0m wandb: Currently logged in as: toribio-diego23 (Cooper-Union) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\u001b[32m [repeated 11x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(train_model pid=4547)\u001b[0m wandb: Tracking run with wandb version 0.19.8\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4547)\u001b[0m wandb: Run data is saved locally in /tmp/ray/session_2025-03-31_01-34-54_021914_1311/artifacts/2025-03-31_01-34-57/mnist_ray_tune/working_dirs/train_model_5aa5c_00010_10_batch_size=32,dropout_rate=0.1450,layer_size=80,lr=0.0001,optimizer=adam_2025-03-31_01-34-57/wandb/run-20250331_013507-f8d00idg\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4547)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4547)\u001b[0m wandb: Syncing run youthful-jazz-71\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4547)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/Cooper-Union/mnist_ray_tune\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4547)\u001b[0m wandb: 🚀 View run at https://wandb.ai/Cooper-Union/mnist_ray_tune/runs/f8d00idg\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 64.2kB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 57.4kB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 132kB/s]\n",
            "  0%|          | 0.00/28.9k [00:00<?, ?B/s]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "  4%|▎         | 360k/9.91M [00:04<01:07, 141kB/s]\u001b[32m [repeated 145x across cluster]\u001b[0m\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 14.4MB/s]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            " 74%|███████▍  | 7.34M/9.91M [00:10<00:01, 2.33MB/s]\u001b[32m [repeated 227x across cluster]\u001b[0m\n",
            "100%|██████████| 9.91M/9.91M [00:10<00:00, 903kB/s] \n",
            " 95%|█████████▍| 9.40M/9.91M [00:10<00:00, 2.84MB/s]\n",
            "100%|██████████| 9.91M/9.91M [00:10<00:00, 904kB/s] \n",
            "100%|██████████| 9.91M/9.91M [00:11<00:00, 901kB/s] \n",
            " 94%|█████████▍| 9.31M/9.91M [00:10<00:00, 2.83MB/s]\n",
            "100%|██████████| 9.91M/9.91M [00:11<00:00, 895kB/s] \n",
            "100%|██████████| 9.91M/9.91M [00:10<00:00, 902kB/s] \n",
            "100%|██████████| 9.91M/9.91M [00:10<00:00, 902kB/s] \n",
            "100%|██████████| 9.91M/9.91M [00:11<00:00, 894kB/s] \n",
            "100%|██████████| 9.91M/9.91M [00:11<00:00, 898kB/s] \n",
            "100%|██████████| 9.91M/9.91M [00:11<00:00, 894kB/s] \n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 183kB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 131kB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 132kB/s]\n",
            "  0%|          | 0.00/1.65M [00:00<?, ?B/s]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "100%|██████████| 1.65M/1.65M [00:07<00:00, 231kB/s]\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: uploading output.log; uploading config.yaml\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.59MB/s]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.21MB/s]\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: uploading wandb-summary.json; uploading config.yaml\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: uploading history steps 2-2, summary\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb:                                                                                \n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: \n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: Run history:\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb:     accuracy ▁▇█\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb:        epoch ▁▅█\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb:         loss █▄▁\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: val_accuracy ▁▆█\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb:     val_loss █▄▁\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: \n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: Run summary:\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb:     accuracy 0.78407\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb:        epoch 3\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb:         loss 1.19287\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: val_accuracy 0.84\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb:     val_loss 0.99916\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: \n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: 🚀 View run graceful-donkey-62 at: https://wandb.ai/Cooper-Union/mnist_ray_tune/runs/r1q0ciam\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: ⭐️ View project at: https://wandb.ai/Cooper-Union/mnist_ray_tune\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[36m(train_model pid=4540)\u001b[0m wandb: Find logs at: ./wandb/run-20250331_013507-r1q0ciam/logs\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb:     accuracy ▁▄█\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: val_accuracy ▁▄█\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: uploading config.yaml; uploading output.log; uploading wandb-summary.json\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: uploading history steps 2-2, summary\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: Run history:\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb:        epoch ▁▅█\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb:         loss █▄▁\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb:     val_loss █▄▁\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: Run summary:\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb:     accuracy 0.20655\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb:        epoch 3\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb:         loss 2.25748\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: val_accuracy 0.2636\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb:     val_loss 2.24513\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: 🚀 View run dulcet-eon-63 at: https://wandb.ai/Cooper-Union/mnist_ray_tune/runs/0mxyw7yx\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: ⭐️ View project at: https://wandb.ai/Cooper-Union/mnist_ray_tune\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[36m(train_model pid=4545)\u001b[0m wandb: Find logs at: ./wandb/run-20250331_013507-0mxyw7yx/logs\n",
            "\u001b[36m(train_model pid=4541)\u001b[0m wandb: uploading output.log; uploading config.yaml\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: uploading output.log; uploading wandb-summary.json\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: Run history:\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb:     accuracy ▁▇█\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb:        epoch ▁▅█\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb:         loss █▂▁\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: val_accuracy ▁▆█\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb:     val_loss █▃▁\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: Run summary:\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb:     accuracy 0.85052\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb:        epoch 3\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb:         loss 0.55625\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: val_accuracy 0.8977\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb:     val_loss 0.41132\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: 🚀 View run feasible-moon-69 at: https://wandb.ai/Cooper-Union/mnist_ray_tune/runs/ypwymmzr\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: ⭐️ View project at: https://wandb.ai/Cooper-Union/mnist_ray_tune\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[36m(train_model pid=4543)\u001b[0m wandb: Find logs at: ./wandb/run-20250331_013507-ypwymmzr/logs\n",
            "\u001b[36m(train_model pid=4541)\u001b[0m wandb: uploading history steps 2-2, summary\n",
            "\u001b[36m(train_model pid=4541)\u001b[0m wandb:     accuracy ▁▄█\n",
            "\u001b[36m(train_model pid=4541)\u001b[0m wandb:         loss █▅▁\n",
            "\u001b[36m(train_model pid=4541)\u001b[0m wandb: val_accuracy ▁▄█\n",
            "\u001b[36m(train_model pid=4541)\u001b[0m wandb:     val_loss █▅▁\n",
            "\u001b[36m(train_model pid=4541)\u001b[0m wandb: 🚀 View run lilac-water-62 at: https://wandb.ai/Cooper-Union/mnist_ray_tune/runs/ipix49kn\n",
            "\u001b[36m(train_model pid=4539)\u001b[0m wandb:     val_loss █▂▁\n",
            "\u001b[36m(train_model pid=4546)\u001b[0m wandb:     accuracy ▁▃█\n",
            "\u001b[36m(train_model pid=4546)\u001b[0m wandb:         loss █▄▁\n",
            "\u001b[36m(train_model pid=4546)\u001b[0m wandb: val_accuracy ▁▅█\n",
            "\u001b[36m(train_model pid=4546)\u001b[0m wandb:     val_loss █▄▁\n",
            "\u001b[36m(train_model pid=4544)\u001b[0m wandb:     accuracy ▁▆█\n",
            "\u001b[36m(train_model pid=4544)\u001b[0m wandb: \u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4550)\u001b[0m wandb: uploading output.log; uploading config.yaml\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb: Run history:\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4549)\u001b[0m wandb:     accuracy ▁▇█\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb:        epoch ▁▅█\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb:         loss █▂▁\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4549)\u001b[0m wandb: val_accuracy ▁▆█\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4549)\u001b[0m wandb:     val_loss █▃▁\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb: Run summary:\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb:     accuracy 0.95892\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb:        epoch 3\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb:         loss 0.14432\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb: val_accuracy 0.9657\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb:     val_loss 0.11465\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb: ⭐️ View project at: https://wandb.ai/Cooper-Union/mnist_ray_tune\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb: Find logs at: ./wandb/run-20250331_013507-7nje4427/logs\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4550)\u001b[0m wandb:     val_loss █▃▁\n",
            "\u001b[36m(train_model pid=4550)\u001b[0m wandb: uploading history steps 2-2, summary\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4544)\u001b[0m wandb:         loss █▅▁\n",
            "\u001b[36m(train_model pid=4550)\u001b[0m wandb: 🚀 View run serene-aardvark-66 at: https://wandb.ai/Cooper-Union/mnist_ray_tune/runs/e4q61830\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4547)\u001b[0m wandb: val_accuracy ▁▅█\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb:     val_loss █▄▁\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4548)\u001b[0m wandb:     accuracy ▁▆█\n",
            "\u001b[36m(train_model pid=4547)\u001b[0m wandb: \u001b[32m [repeated 16x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: uploading output.log; uploading config.yaml\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: Run history:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb:     accuracy ▁▇█\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb:        epoch ▁▅█\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb:         loss █▂▁\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4550)\u001b[0m wandb: val_accuracy ▁▆█\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: Run summary:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb:     accuracy 0.90555\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb:        epoch 3\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb:         loss 0.33301\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: val_accuracy 0.9242\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb:     val_loss 0.26995\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: ⭐️ View project at: https://wandb.ai/Cooper-Union/mnist_ray_tune\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: Find logs at: ./wandb/run-20250331_013506-8n49cv7c/logs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb:     val_loss █▃▁\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: uploading history steps 2-2, summary\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: 🚀 View run efficient-butterfly-62 at: https://wandb.ai/Cooper-Union/mnist_ray_tune/runs/8n49cv7c\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: val_accuracy ▁▅█\n",
            "\u001b[36m(train_model pid=4542)\u001b[0m wandb: \u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune import Tuner, TuneConfig\n",
        "from ray.air import RunConfig\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Single config dictionary with all parameters\n",
        "config = {\n",
        "    \"wandb_api_key\": \"KEY\",\n",
        "    \"ngrok_auth_token\": \"KEY\",\n",
        "    \"resource\": {\n",
        "        \"total_cpus\": 12,\n",
        "        \"num_tasks\": 12,\n",
        "        \"cpus_per_task\": 1,\n",
        "        \"gpus_per_task\": 0\n",
        "    },\n",
        "    \"tune_params\": {\n",
        "        \"lr\": tune.loguniform(1e-5, 1e-2),\n",
        "        \"batch_size\": tune.choice([32, 64, 128]),\n",
        "        \"optimizer\": tune.choice([\"adam\", \"sgd\"]),\n",
        "        \"layer_size\": tune.randint(64, 256),\n",
        "        \"dropout_rate\": tune.uniform(0.1, 0.5),\n",
        "        \"epochs\": 3\n",
        "    }\n",
        "}\n",
        "\n",
        "wandb.login(key=config[\"wandb_api_key\"])\n",
        "ngrok.set_auth_token(config[\"ngrok_auth_token\"])\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, layer_size=128, dropout_rate=0.3, **kwargs):\n",
        "        super(CustomModel, self).__init__(**kwargs)\n",
        "        self.fc1 = nn.Linear(784, layer_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(layer_size, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "def train_model(tune_config):\n",
        "    run = wandb.init(project=\"mnist_ray_tune\", config=tune_config)\n",
        "    train_dataset = MNIST(root=\"data\", train=True, transform=ToTensor(), download=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=tune_config[\"batch_size\"], shuffle=True)\n",
        "    test_dataset = MNIST(root=\"data\", train=False, transform=ToTensor(), download=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = CustomModel(layer_size=tune_config[\"layer_size\"], dropout_rate=tune_config[\"dropout_rate\"])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=tune_config[\"lr\"]) if tune_config[\"optimizer\"] == \"adam\" else optim.SGD(model.parameters(), lr=tune_config[\"lr\"])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(tune_config[\"epochs\"]):\n",
        "        model.train()\n",
        "        train_loss_sum, train_correct, train_total = 0.0, 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss_sum += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "        train_loss = train_loss_sum / len(train_loader)\n",
        "        train_accuracy = train_correct / train_total\n",
        "\n",
        "        model.eval()\n",
        "        val_loss_sum, val_correct, val_total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss_val = criterion(outputs, labels)\n",
        "                val_loss_sum += loss_val.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "        val_loss = val_loss_sum / len(test_loader)\n",
        "        val_accuracy = val_correct / val_total\n",
        "\n",
        "        wandb.log({\n",
        "            \"loss\": train_loss,\n",
        "            \"accuracy\": train_accuracy,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_accuracy,\n",
        "            \"epoch\": epoch + 1\n",
        "        })\n",
        "        tune.report({\n",
        "            \"loss\": train_loss,\n",
        "            \"accuracy\": train_accuracy,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_accuracy,\n",
        "            \"epoch\": epoch + 1\n",
        "        })\n",
        "    run.finish()\n",
        "\n",
        "def run_ray_tune(cfg):\n",
        "    ray.shutdown()\n",
        "    ray.init(num_cpus=cfg[\"resource\"][\"total_cpus\"],\n",
        "             ignore_reinit_error=True,\n",
        "             logging_level=\"ERROR\",\n",
        "             include_dashboard=True)\n",
        "    public_url = ngrok.connect(8265, \"http\")\n",
        "    print(\"Public URL for Ray Dashboard:\", public_url)\n",
        "    print(\"Ray available resources:\", ray.available_resources())\n",
        "\n",
        "    tuner = Tuner(\n",
        "        tune.with_resources(train_model, resources={\n",
        "            \"cpu\": cfg[\"resource\"][\"cpus_per_task\"],\n",
        "            \"gpu\": cfg[\"resource\"][\"gpus_per_task\"]\n",
        "        }),\n",
        "        param_space=cfg[\"tune_params\"],\n",
        "        tune_config=TuneConfig(num_samples=cfg[\"resource\"][\"num_tasks\"], scheduler=None),\n",
        "        run_config=RunConfig(name=\"mnist_ray_tune\", verbose=0)\n",
        "    )\n",
        "    results = tuner.fit()\n",
        "    timeline_data = ray.timeline()\n",
        "    with open(\"timeline.json\", \"w\") as f:\n",
        "        f.write(json.dumps(timeline_data, indent=2))\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    run_ray_tune(config)\n",
        "    ray.shutdown()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!htop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8InsQM-r-wjt",
        "outputId": "9cfb1fe8-99ad-4e4d-c76e-ec11542e6815"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: htop: command not found\n"
          ]
        }
      ]
    }
  ]
}